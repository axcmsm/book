(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{481:function(a,s,t){"use strict";t.r(s);var n=t(16),r=Object(n.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h4",{attrs:{id:"_1、初识flink"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、初识flink"}},[a._v("#")]),a._v(" 1、初识Flink")]),a._v(" "),t("p",[a._v("Flink是一个开源的分布式流处理框架，它被设计用来在大规模数据集上进行实时、高效的数据流处理。Flink支持多种计算模型，包括基于流(streaming)的数据处理和批处理(batch)处理。相对于传统的流处理框架，例如Apache Storm和Kafka Streams，Flink的主要优点在于其高度可扩展性和容错性。Flink使用了基于流和状态的计算模型，并提供了不同级别的延迟保证和一致性保证，因此可以处理极端情况下的异常数据。Flink提供的API丰富，包括Java和Scala。同时，Flink还提供了一些高级功能，例如处理时间、窗口函数和迭代计算等。Flink具备很好的良好的集成能力，与Apache Hadoop、Apache Kafka、Apache Cassandra、Elasticsearch等开源软件都可以无缝整合。")]),a._v(" "),t("p",[a._v("Flink是一个非常强大的流处理框架，可以帮助我们高效地处理大规模的数据流，提高企业的数据处理效率。")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://flink.apache.org/zh/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Apache Flink Documentation | Apache Flink"),t("OutboundLink")],1)]),a._v(" "),t("h4",{attrs:{id:"_2、flink的适用场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、flink的适用场景"}},[a._v("#")]),a._v(" 2、Flink的适用场景")]),a._v(" "),t("p",[a._v("Flink的适用场景主要包括以下几个方面：")]),a._v(" "),t("ol",[t("li",[a._v("事件驱动型应用：这种类型的应用程序需要处理实时的数据流，例如物联网、传感器数据处理、实时监控等场景。")]),a._v(" "),t("li",[a._v("数据分析应用：Flink可以处理大规模的批量数据，同时还能进行多维度分析、机器学习预测等操作，非常适合大规模数据分析和挖掘场景。")]),a._v(" "),t("li",[a._v("数据管道应用：Flink可以将多个数据源的数据收集到一起，进行数据预处理、清洗和转换，最终输出到目标数据存储系统中，例如大数据仓库、搜索引擎等。")])]),a._v(" "),t("p",[a._v("Flink作为一个强大的流处理和批处理框架，流批一体，适用于大部分涉及到实时数据处理和大数据分析需求的场景。")]),a._v(" "),t("p",[a._v("例如，常见典型应用场景包括实时监控系统，推荐系统，日志分析系统等。")]),a._v(" "),t("h4",{attrs:{id:"_3、流式计算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、流式计算"}},[a._v("#")]),a._v(" 3、流式计算")]),a._v(" "),t("p",[t("strong",[a._v("流式计算处理的思路")]),a._v("：基于微批处理的方式和基于事件驱动的方式。")]),a._v(" "),t("ol",[t("li",[t("strong",[a._v("基于微批处理的方式")]),a._v("：这种方式将数据流划分成微批次，并对每个微批次进行处理。常见的代表包括Spark Streaming和Kinesis Analytics等。它的优点是易于实现以及提供了一些批处理的特性，例如事务处理和容错性。但是其缺点也很明显，处理延迟较高，不适合要求处理实时性较高的场景。")]),a._v(" "),t("li",[t("strong",[a._v("基于事件驱动的方式")]),a._v("：这种方式是按照事件在数据流中的到达时间来处理数据的。常见的代表包括Flink和Kafka Streams等。它的优点是可以实现真正意义上的实时处理和低延迟，同时能够支持复杂的事件处理和状态保存等高级功能。")])]),a._v(" "),t("p",[t("strong",[a._v("其中Kafka Streams、Spark Streaming和Flink都是流处理计算框架")]),a._v("，它们各有特点。")]),a._v(" "),t("ol",[t("li",[a._v("Kafka Streams：是一个轻量级的流处理框架，与Kafka集成紧密，可以使用Kafka作为数据输入和输出源。其设计目标是尽可能简单而轻量，并且仅依赖于Kafka作为基础设施。")]),a._v(" "),t("li",[a._v("Spark Streaming：是Spark生态系统中负责流处理的模块，通过将数据流分成小批次来处理数据，因此具有较低的时延和较高的容错性。它的优点是易于集成到已有的Spark生态系统中。")]),a._v(" "),t("li",[a._v("Flink：是一个流处理、批处理及机器学习计算框架，由于其"),t("strong",[a._v("基于事件驱动")]),a._v("和"),t("strong",[a._v("状态管理")]),a._v("的计算模型，可以执行复杂的流处理任务并支持较低的时延和高级的状态管理或迭代计算功能，较为适合处理大量数据源的实时解决方案。")])]),a._v(" "),t("h2",{attrs:{id:"二、flink安装部署-todo"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二、flink安装部署-todo"}},[a._v("#")]),a._v(" 二、Flink安装部署(todo)")]),a._v(" "),t("h4",{attrs:{id:"部署的方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#部署的方式"}},[a._v("#")]),a._v(" 部署的方式")]),a._v(" "),t("p",[a._v("Flink部署的方式非常多，Local，Standalone，Yarn，Messos，Docker，K8s，AWS都可以支持。其中，我们主要关注Local，Standalone，Yarn三种。")]),a._v(" "),t("p",[t("strong",[a._v("Local")]),a._v("：不单独部署运行环境，在代码中直接调试。")]),a._v(" "),t("p",[t("strong",[a._v("Standalone")]),a._v("：独立运行环境。这个情况下，Flink完全自己管理运行资源。这种方式，其实资源的利用率是比较低的。")]),a._v(" "),t("p",[t("strong",[a._v("Yarn")]),a._v("：以Hadoop提供的Yarn作为资源管理服务。这这样可以更加高效的使用集群的机器资源。")]),a._v(" "),t("p",[t("strong",[a._v("安装包下载地址")]),a._v("："),t("a",{attrs:{href:"https://dlcdn.apache.org/flink/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Index of /flink (apache.org)"),t("OutboundLink")],1)]),a._v(" "),t("blockquote",[t("p",[a._v("注意：scala版本的选择，2.12和2.11的版本兼容是不一样的，但是我们下载的运行后的版本，而scala的运行只依靠JVM去运行即可，固然下载那个版本都可以，并且在机器上也可以不安装scala环境，但是一定要配置Jdk环境。")])]),a._v(" "),t("h4",{attrs:{id:"standalone部署"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#standalone部署"}},[a._v("#")]),a._v(" Standalone部署")]),a._v(" "),t("p",[t("strong",[a._v("Flink")]),a._v(" "),t("strong",[a._v("程序中如果要访问到个hdfs则需要添加2jar包到flink的 lib目录中")])]),a._v(" "),t("ul",[t("li",[t("p",[t("em",[a._v("flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar")])])]),a._v(" "),t("li",[t("p",[t("em",[a._v("commons-cli-1.4.jar")])])])]),a._v(" "),t("p",[t("strong",[a._v("部署")]),a._v("：")]),a._v(" "),t("ol",[t("li",[t("p",[t("strong",[a._v("下载安装包")]),a._v(" （使用wget 或者直接到官网下载)")]),a._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#下载安装包")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wget")]),a._v(" https://archive.apache.org/dist/flink/flink-1.17.0/flink-1.17.0-bin-scala_2.12.tgz\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#解压到 /opt 目录")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("tar")]),a._v(" -xzvf flink-1.17.0-bin-scala_2.12.tgz -C /opt/\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br")])])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("配置Flink")])]),a._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(". conf/master 配置 JobManager 地址\n    master:8081\n\n"),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(". conf/workers 配置 TaskManager 机器地址\nmaster\nslave1\nslave2\n\n"),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(". conf/flink-conf.yaml 程序参数配置\njobmanager.rpc.address: master\ntaskmanager.numberOfTaskSlots: "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br")])])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("集群启停命令")])]),a._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("bin/start-cluster.sh\nbin/stop-cluster.sh\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("应用提交")])]),a._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(". 通过 web ui 提交 job\n\n"),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(". 通过命令 bin/flink run 提交 job\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 提交 standalone 模式的 job")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# -c 主类名")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# -p 并行度")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# -s 从指定 savepoint 恢复")]),a._v("\nbin/flink run -t remote "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n-c cn.doitedu.flink.java.demos._28_ToleranceSideToSideTest "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n-p "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n-s hdfs://master:8020/eos_savepoint1/savepoint-5f1bc3-dde7a8627fff "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n/root/flink_course-1.0.jar\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 触发 standalone 模式 job 做 savepoint")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# -d : detach 模式，客户端提交完 job 即退出")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# -t remote : 表示 job 是 standalone 运行模式")]),a._v("\nbin/flink savepoint -t remote 5f1bc357bfd1e686e34b6cfce6d0cda9 hdfs://master:8020/eos_savepoint1\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br"),t("span",{staticClass:"line-number"},[a._v("15")]),t("br"),t("span",{staticClass:"line-number"},[a._v("16")]),t("br"),t("span",{staticClass:"line-number"},[a._v("17")]),t("br")])])])]),a._v(" "),t("h4",{attrs:{id:"yarn部署"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#yarn部署"}},[a._v("#")]),a._v(" Yarn部署")]),a._v(" "),t("h4",{attrs:{id:"任务的提交"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#任务的提交"}},[a._v("#")]),a._v(" 任务的提交")]),a._v(" "),t("h2",{attrs:{id:"三、运行架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#三、运行架构"}},[a._v("#")]),a._v(" 三、运行架构")]),a._v(" "),t("h4",{attrs:{id:"_1、jomanager和taskmanager"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、jomanager和taskmanager"}},[a._v("#")]),a._v(" 1、JoManager和TaskManager")]),a._v(" "),t("ul",[t("li",[t("p",[t("strong",[a._v("JobManager")]),a._v("：处理作业的整体协调与调度，负责作业提交、停止和恢复等操作 => master。")])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("TaskManager")]),a._v("：是一个工作进程，每个TaskManager可以执行多个并发任务（Task），负责作业的具体执行。它从JobManager获取作业任务并分配给任务slot，同时在TaskManager上执行任务的数据流  => worker。")])]),a._v(" "),t("li",[t("p",[t("strong",[a._v("其他组件")]),a._v("：")]),a._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("ResourceManager：负责管理Flink集群的资源，包括TaskManager的数量、容量等。它与JobManager交互，并调度计算服务运行状态，以及负责动态地为作业分配更多的资源。\nBlobServer：存储Flink集群的jar和其他二进制文件，如序列化器、类库等。\nWeb Frontend：提供Web UI来监控Flink集群和作业\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])])])]),a._v(" "),t("p",[t("strong",[a._v("Flink执行一个任务的过程可以分为三个主要阶段")]),a._v(":")]),a._v(" "),t("ol",[t("li",[t("strong",[a._v("作业提交")]),a._v("：该阶段涉及将Flink应用程序打包成二进制文件，并将其提交到JobManager。在此过程中，任务管理器（TaskManager）也会被启动并且准备好接受任务。")]),a._v(" "),t("li",[t("strong",[a._v("作业执行")]),a._v("：一旦作业被成功提交，Flink系统将分配资源来运行该作业。JobManager负责作业的整体协调与调度，将作业分割成多个任务（Task），每个任务由一个或多个操作子任务组成。JobManager将子任务分配给TaskManager执行，并定期检查子任务的状态，以便在必要时重新调度或重新启动失败的子任务。TaskManager负责处理它们完成的所有子任务，并在合适的时机将结果发送回JobManager。")]),a._v(" "),t("li",[t("strong",[a._v("作业结束")]),a._v("：一旦作业完成，JobManager将释放所有使用的资源，并向用户提供作业的执行结果。该结果可以通过Web UI和Flink客户端API获取，并且可以进一步导出到外部系统以进行后续分析。")])]),a._v(" "),t("h4",{attrs:{id:"_2、并发度与slots"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、并发度与slots"}},[a._v("#")]),a._v(" 2、并发度与Slots")]),a._v(" "),t("p",[t("strong",[a._v("并发度（"),t("strong",[a._v("Parallelism）"),t("strong",[a._v("是")]),a._v("指在")]),a._v("作业执行时并行执行的任务数")]),a._v("，即在同一时间内可以同时处理的任务数。而"),t("strong",[a._v("Slots")]),a._v("则"),t("strong",[a._v("是指每个TaskManager节点")]),a._v("所拥有的资源数量，它决定了该节点"),t("strong",[a._v("能够同时处理多少个任务")]),a._v("。因此，并发度和Slots是紧密相关的概念。")]),a._v(" "),t("p",[a._v("具体来讲，Flink将并发度分为两种："),t("strong",[a._v("任务并发度和算子并发度")]),a._v("["),t("a",{attrs:{href:"https://ci.apache.org/projects/flink/flink-docs-stable/dev/parallel.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("2"),t("OutboundLink")],1),a._v("]。任务并发度指的是整个作业并行执行的任务数，通常通过对整个作业进行配置来设置。而算子并发度指的是每个算子（如Map、Filter、Aggregate等）在运行时可以并行处理的任务数。")]),a._v(" "),t("p",[a._v("例如，假设我们有一个包含10个分区的输入数据集合，我们可以将其分配给2个任务并行处理，每个任务处理5个分区。这就是任务并发度为2的情况。而对于单个算子而言，算子并发度为3表示该算子能够同时处理3个任务。")]),a._v(" "),t("p",[a._v("在Flink中，Slots是由TaskManager所提供的，它们用于管理可用资源，如CPU、内存等。每个TaskManager可以配置多个Slots，每个Slot都有一定的资源限制。在作业运行时，JobManager会将任务分配到可用的Slots上，从而实现任务的并行执行。")]),a._v(" "),t("p",[a._v("以一个简单的例子来说明并发度和Slots的概念。假设我们有一个包含100个事件的数据流，每个事件都需要进行计算，需要使用100个TaskManager来执行任务。如果我们将并发度设置为50，那么每个TaskManager将会处理2个事件。如果我们分配了200个Slots，那么每个TaskManager将能够同时处理两个计算任务。")]),a._v(" "),t("h4",{attrs:{id:"_3、整体运行流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、整体运行流程"}},[a._v("#")]),a._v(" 3、整体运行流程")]),a._v(" "),t("ol",[t("li",[a._v("从源头读取数据：Flink 可以从多种数据源读取数据，包括文件、Kafka 等。一旦 Flink 开始读取数据，它会把数据分发到不同的 TaskManager（任务管理器）节点。")]),a._v(" "),t("li",[a._v("数据转换：Flink 提供了多种运算符和转换器，允许用户对数据流进行转换操作，例如 Map、Filter、Reduce 等。这些运算符通常被组合在一起来形成一个完整的数据处理流程。")]),a._v(" "),t("li",[a._v("任务调度：Flink 使用自己的任务调度器来分配任务到 TaskManager 节点。任务调度器会尝试将相邻任务分配给同一个 TaskManager 节点，以最大化性能。")]),a._v(" "),t("li",[a._v("数据分区：Flink 将数据流分成并行的子流，每个子流都由一个或多个 TaskManager 节点处理。数据分区的方法可以通过用户定义的键、随机哈希函数等方式实现。")]),a._v(" "),t("li",[a._v("并行执行：Flink 在每个节点上都运行多个任务，这些任务可能在多个线程中同时运行。Flink 的并行度是动态管理的，可以在运行时根据需要自动调整。")]),a._v(" "),t("li",[a._v("写回结果：一旦 Flink 完成计算，它会将结果写回到外部系统、文件或其他位置。")])]),a._v(" "),t("h2",{attrs:{id:"四、flink-datastream-api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#四、flink-datastream-api"}},[a._v("#")]),a._v(" 四、Flink DataStream API")]),a._v(" "),t("h4",{attrs:{id:"_1、flink程序的基础运行模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、flink程序的基础运行模型"}},[a._v("#")]),a._v(" 1、Flink程序的基础运行模型")]),a._v(" "),t("h4",{attrs:{id:"_2、environment-运行环境"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、environment-运行环境"}},[a._v("#")]),a._v(" 2、Environment 运行环境")]),a._v(" "),t("h4",{attrs:{id:"_3、source"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、source"}},[a._v("#")]),a._v(" 3、Source")]),a._v(" "),t("h4",{attrs:{id:"_4、sink"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、sink"}},[a._v("#")]),a._v(" 4、Sink")]),a._v(" "),t("h4",{attrs:{id:"_5、transformation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5、transformation"}},[a._v("#")]),a._v(" 5、Transformation")]),a._v(" "),t("h4",{attrs:{id:"_6、window-开窗"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6、window-开窗"}},[a._v("#")]),a._v(" 6、Window 开窗")]),a._v(" "),t("h4",{attrs:{id:"_7、cep编程模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7、cep编程模型"}},[a._v("#")]),a._v(" 7、CEP编程模型")]),a._v(" "),t("h2",{attrs:{id:"五、flink-时间语义"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#五、flink-时间语义"}},[a._v("#")]),a._v(" 五、Flink 时间语义")]),a._v(" "),t("h4",{attrs:{id:"_1、flink的三种自然时间语义"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、flink的三种自然时间语义"}},[a._v("#")]),a._v(" 1、Flink的三种自然时间语义")]),a._v(" "),t("h4",{attrs:{id:"_2、设置eventtime"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、设置eventtime"}},[a._v("#")]),a._v(" 2、设置EventTime")]),a._v(" "),t("h4",{attrs:{id:"_3、如何处理乱序数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、如何处理乱序数据"}},[a._v("#")]),a._v(" 3、如何处理乱序数据")]),a._v(" "),t("ol",[t("li",[a._v("水位线")]),a._v(" "),t("li",[a._v("允许等待时间")]),a._v(" "),t("li",[a._v("侧输出流")])]),a._v(" "),t("h2",{attrs:{id:"六、flink-table-和-flink-sql"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#六、flink-table-和-flink-sql"}},[a._v("#")]),a._v(" 六、Flink Table 和 Flink SQL")]),a._v(" "),t("h4",{attrs:{id:"基本使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基本使用"}},[a._v("#")]),a._v(" 基本使用")]),a._v(" "),t("h4",{attrs:{id:"基础编程框架"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基础编程框架"}},[a._v("#")]),a._v(" 基础编程框架")]),a._v(" "),t("h4",{attrs:{id:"扩展编程框架"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩展编程框架"}},[a._v("#")]),a._v(" 扩展编程框架")]),a._v(" "),t("h2",{attrs:{id:"七、flink状态机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#七、flink状态机制"}},[a._v("#")]),a._v(" 七、Flink状态机制")]),a._v(" "),t("h4",{attrs:{id:"_1、operator-state-算子状态"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、operator-state-算子状态"}},[a._v("#")]),a._v(" 1、Operator State 算子状态")]),a._v(" "),t("h4",{attrs:{id:"_2、keyed-state-键控状态"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、keyed-state-键控状态"}},[a._v("#")]),a._v(" 2、Keyed State 键控状态")]),a._v(" "),t("h4",{attrs:{id:"_3、checkpointing-检查点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、checkpointing-检查点"}},[a._v("#")]),a._v(" 3、Checkpointing 检查点")]),a._v(" "),t("h4",{attrs:{id:"_4、容错重启机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、容错重启机制"}},[a._v("#")]),a._v(" 4、容错重启机制")]),a._v(" "),t("h4",{attrs:{id:"_5、state-backend-状态存储方式与位置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5、state-backend-状态存储方式与位置"}},[a._v("#")]),a._v(" 5、State Backend 状态存储方式与位置")]),a._v(" "),t("h2",{attrs:{id:"项目案例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#项目案例"}},[a._v("#")]),a._v(" 项目案例")]),a._v(" "),t("ol",[t("li",[a._v("需求背景")]),a._v(" "),t("li",[a._v("数据流程设计")]),a._v(" "),t("li",[a._v("应用实现")]),a._v(" "),t("li",[a._v("实现效果")])]),a._v(" "),t("p",[t("strong",[a._v("学习代码")]),a._v("：...")])])}),[],!1,null,null,null);s.default=r.exports}}]);